{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS 284N Text Analysis Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Siqi Chen, Jiayan Lu, Joshua Larky, Jinru Su, Korawat Tanwisuth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from pandas import Series, DataFrame\n",
    "from collections import Counter, defaultdict\n",
    "from operator import itemgetter\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = pd.read_csv('~/Downloads/Train_rev1.csv',usecols=['FullDescription','SalaryNormalized'])\n",
    "job_sample = job.sample(n=10000,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_sample['tokens'] = job_sample['FullDescription'].map(word_tokenize)\n",
    "words = job_sample['tokens'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tag_counts = defaultdict(int)\n",
    "for (word, tag) in nltk.pos_tag(words): \n",
    "    tag_counts[tag] += 1\n",
    "sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "top_100 = Counter(words).most_common(100)\n",
    "c_rank = ss.rankdata([c for (w, c) in top_100])\n",
    "rev = [100-r+1 for r in c_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = subplots(nrows=1,\n",
    "                           ncols=2,\n",
    "                           figsize=(12, 4))\n",
    "ax1.plot([c for c in rev], [c for (w, c) in top_100], 'o')\n",
    "ax1.set_xlabel('rank')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.set_title('Frequency vs Rank')\n",
    "\n",
    "ax2.plot([np.log(c) for c in rev], [np.log(c) for (w, c) in top_100], 'o')\n",
    "ax2.set_xlabel('log(rank)')\n",
    "ax2.set_ylabel('log(frequency)')\n",
    "ax2.set_title('log(Frequency) vs log(Rank)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot on the left shows word frequency is inversely proportional to its rank, which satisfies Zipf's law. \n",
    "\n",
    "Plot on the right shows word frequency decreases at a lower rate for higher ranks. $k$ is approximately $\\frac{11.5-11}{2} = 0.25$ for rank 1 to 7 ($ e^{2}$), and increase to approximately $\\frac{11-8}{4.6-2} = 1.15$ for rank 7 to 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "words_nonstop_lemma = [wnl.lemmatize(w) for w in words if w not in stopwords]\n",
    "words_nonstop_lemma_dist = nltk.FreqDist(words_nonstop_lemma) \n",
    "rslt = pd.DataFrame(words_nonstop_lemma_dist.most_common(10),\n",
    "                    columns=['Word', 'Frequency'])\n",
    "rslt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_sample['target'] = 'low'\n",
    "thresh_75 = job_sample['SalaryNormalized'].quantile(.75)\n",
    "job_sample.loc[job_sample['SalaryNormalized'] >= thresh_75,'target'] = 'high'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_data = job_sample['FullDescription'].str.lower().tolist()\n",
    "job_label = job_sample['target'].tolist()\n",
    "\n",
    "trainset_size = int(len(job_data)*0.7)\n",
    "\n",
    "X_train = np.array([el for el in job_data[0:trainset_size]])\n",
    "y_train = np.array([el for el in job_label[0:trainset_size]])\n",
    "\n",
    "X_test = np.array([el for el in job_data[trainset_size:len(job_data)]]) \n",
    "y_test = np.array([el for el in job_label[trainset_size:len(job_label)]]) \n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = vectorizer.fit_transform(X_train)\n",
    "X_test_all = vectorizer.transform(X_test)\n",
    "\n",
    "nb_classifier = MultinomialNB().fit(X_train_all, y_train)\n",
    "y_nb_predicted = nb_classifier.predict(X_test_all)\n",
    "\n",
    "print ('\\nHere is the accuracy score:')\n",
    "print (metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print ('\\nHere is the confusion matrix:')\n",
    "print (pd.crosstab(y_test,y_nb_predicted,rownames=['actual'], colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization will reduce total number of words by grouping the inflected words as a single item and increase the prediction power of informative features. Hence we speculate that prediction accuracy will increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = nltk.WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]        \n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=LemmaTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_lemma = vectorizer.fit_transform(X_train)\n",
    "X_test_lemma = vectorizer.transform(X_test)\n",
    "\n",
    "nb_classifier = MultinomialNB().fit(X_train_lemma, y_train)\n",
    "y_nb_predicted = nb_classifier.predict(X_test_lemma)\n",
    "\n",
    "print ('\\nHere is the accuracy score:')\n",
    "print (metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print ('\\nHere is the confusion matrix:')\n",
    "print (pd.crosstab(y_test,y_nb_predicted,rownames=['actual'], colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction accuracy increases around 1.2% comparing to B1. Lemmatization helps prediction accuracy as we speculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as lemmatization, removing stopwords will reduce total number of words, increasing the relative frequency of informative features. Hence we speculate that prediction accuracy will increase as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_nonstop = vectorizer.fit_transform(X_train)\n",
    "X_test_nonstop = vectorizer.transform(X_test)\n",
    "\n",
    "nb_classifier = MultinomialNB().fit(X_train_nonstop, y_train)\n",
    "y_nb_predicted = nb_classifier.predict(X_test_nonstop)\n",
    "\n",
    "print ('\\nHere is the accuracy score:')\n",
    "print (metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print ('\\nHere is the confusion matrix:')\n",
    "print (pd.crosstab(y_test,y_nb_predicted,rownames=['actual'], colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction accuracy increases around 0.03% comparing to B1. The effect of removing stopwords on prediction accuracy is much smaller comparing to lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_most_informative_features(vectorizer, clf, n=10):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(nb_classifier.coef_[0], feature_names))\n",
    "    top_low = [fn for (coef,fn) in coefs_with_fns[:n]]\n",
    "    top_high = [fn for (coef,fn) in coefs_with_fns[:-(n + 1):-1]]\n",
    "    print ('\\n The top %d most informative features for low salary: \\n %s'%(n,','.join(top_low))) \n",
    "    print ('\\n The top %d most informative features for high salary: \\n %s'%(n,','.join(top_high)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_most_informative_features(vectorizer, nb_classifier, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bi_words(x):\n",
    "    tokens = word_tokenize(x.lower())\n",
    "    pos = nltk.pos_tag(tokens)\n",
    "    tag_list = []\n",
    "    for p in pos:\n",
    "        tag_list.append(p[1])\n",
    "    bigrams = ngrams(tag_list,2)\n",
    "    return ' '.join(tokens + [''.join(grams) for grams in bigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job_sample['word_tag'] = job_sample['FullDescription'].apply(bi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_data = job_sample['word_tag'].tolist()\n",
    "tag_train = np.array([el for el in tag_data[0:trainset_size]])\n",
    "tag_test = np.array([el for el in tag_data[trainset_size:len(tag_data)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_tag = vectorizer.fit_transform(tag_train)\n",
    "X_test_tag = vectorizer.transform(tag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB().fit(X_train_tag, y_train)\n",
    "y_nb_predicted = nb_classifier.predict(X_test_tag)\n",
    "\n",
    "print ('\\nHere is the accuracy score:')\n",
    "print (metrics.accuracy_score(y_test, y_nb_predicted))\n",
    "\n",
    "print ('\\nHere is the confusion matrix:')\n",
    "print (pd.crosstab(y_test,y_nb_predicted,rownames=['actual'], colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction accuracy after adding POS bigrams to bag-of-words decreases slightly by 0.17% comparing to B1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
